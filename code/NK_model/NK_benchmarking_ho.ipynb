{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T11:37:33.083248Z",
     "start_time": "2025-03-28T11:37:33.080244Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn import decomposition\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T11:37:34.937237Z",
     "start_time": "2025-03-28T11:37:34.931835Z"
    }
   },
   "outputs": [],
   "source": [
    "def latin_sampling(num):\n",
    "    xlimits = np.array([[0,1.0]]*10)\n",
    "    sampling = LHS(xlimits=xlimits,)\n",
    "    x = sampling(num)\n",
    "    sequence_list=[]\n",
    "    for i in range(num):\n",
    "        oh=\"\"\n",
    "        for j in range(10):\n",
    "            if x[i][j]<0.25:\n",
    "                oh=oh+\"A\"\n",
    "            elif x[i][j]<0.5:\n",
    "                oh=oh+\"C\"\n",
    "            elif x[i][j]<0.75:\n",
    "                oh=oh+\"G\"\n",
    "            elif x[i][j]<1:\n",
    "                oh=oh+\"T\"             \n",
    "        sequence_list.append(oh)\n",
    "    return sequence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T11:37:35.329660Z",
     "start_time": "2025-03-28T11:37:35.324916Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_sampling(num):\n",
    "    x= np.random.random_sample((num,10))\n",
    "    sequence_list=[]\n",
    "    for i in range(num):\n",
    "        oh=\"\"\n",
    "        for j in range(10):\n",
    "            if x[i][j]<0.25:\n",
    "                oh=oh+\"A\"\n",
    "            elif x[i][j]<0.5:\n",
    "                oh=oh+\"C\"\n",
    "            elif x[i][j]<0.75:\n",
    "                oh=oh+\"G\"\n",
    "            elif x[i][j]<1:\n",
    "                oh=oh+\"T\"             \n",
    "        sequence_list.append(oh)\n",
    "    return sequence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T11:37:35.679839Z",
     "start_time": "2025-03-28T11:37:35.674020Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_input_type(seq, target_type):\n",
    "    \"\"\"\n",
    "    Convert DNA sequence between string and one-hot encoded representations.\n",
    "\n",
    "    Args:\n",
    "        seq: The input DNA sequence(s).\n",
    "        target_type: The target representation type (\"one_hot\" or \"strings\").\n",
    "\n",
    "    Returns:\n",
    "        The converted DNA sequence(s).\n",
    "    \"\"\"\n",
    "    if target_type == \"one_hot\":\n",
    "        # Convert string to one-hot encoded numpy array\n",
    "        mapping = {'A': [1, 0, 0, 0], 'C': [0, 1, 0, 0], 'G': [0, 0, 1, 0], 'T': [0, 0, 0, 1]}\n",
    "        one_hot = np.array([mapping[base] for base in seq])\n",
    "        return one_hot\n",
    "    elif target_type == \"strings\":\n",
    "        # Convert one-hot encoded numpy array to string\n",
    "        mapping = {0: 'A', 1: 'C', 2: 'G', 3: 'T'}\n",
    "        strings = ''.join([mapping[np.argmax(base)] for base in seq])\n",
    "        return strings\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported target_type. Use 'one_hot' or 'strings'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T11:50:12.279682Z",
     "start_time": "2025-03-28T11:50:12.271118Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gradient Descent\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from typing import Optional, Callable, List\n",
    "\n",
    "def convert_input_type(seq, target_type):\n",
    "    mapping = {'A': [1, 0, 0, 0], 'C': [0, 1, 0, 0], 'G': [0, 0, 1, 0], 'T': [0, 0, 0, 1]}\n",
    "    if target_type == \"one_hot\":\n",
    "        one_hot = np.array([mapping[base] for base in seq]).flatten()\n",
    "        return one_hot\n",
    "    elif target_type == \"strings\":\n",
    "        reverse_mapping = {tuple(v): k for k, v in mapping.items()}\n",
    "        reshaped_seq = seq.reshape(-1, 4)\n",
    "        strings = ''.join([reverse_mapping[tuple(base)] for base in reshaped_seq])\n",
    "        return strings\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported target_type. Use 'one_hot' or 'strings'.\")\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=-1, keepdims=True)\n",
    "\n",
    "def closest_one_hot(x):\n",
    "    one_hot = np.zeros_like(x)\n",
    "    one_hot[np.argmax(x)] = 1\n",
    "    return one_hot\n",
    "\n",
    "def gradient_descent_optimization(\n",
    "    seq: str,\n",
    "    model: MLPRegressor,\n",
    "    loss_func: Callable,\n",
    "    learning_rate: float = 1,\n",
    "    max_iter: int = 200,\n",
    "    positions: Optional[List[int]] = None,\n",
    "    grad_clip: float = 1.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Sequence design using gradient descent optimization with MLPRegressor\n",
    "\n",
    "    Args:\n",
    "        seq: an initial DNA sequence as a string.\n",
    "        model: A trained MLPRegressor object\n",
    "        loss_func: A function to compute the loss\n",
    "        learning_rate: Learning rate for gradient descent\n",
    "        max_iter: Number of iterations\n",
    "        positions: Positions to mutate. If None, all positions will be mutated\n",
    "        grad_clip: Gradient clipping value\n",
    "\n",
    "    Returns:\n",
    "        Optimized DNA sequence as a string and its prediction value.\n",
    "    \"\"\"\n",
    "    # Convert sequence into a one-hot encoded tensor\n",
    "    X = convert_input_type(seq, \"one_hot\").reshape(1, -1).astype(float)\n",
    "    # print(f\"Initial shape of X: {X.shape}\")\n",
    "\n",
    "    best_X = X.copy()\n",
    "    best_y = model.predict(X)\n",
    "    best_loss = loss_func(best_y)\n",
    "    # print(f\"Initial loss: {best_loss}\")\n",
    "\n",
    "    # Gradient descent optimization\n",
    "    for i in range(max_iter):\n",
    "        # Forward pass\n",
    "        y_pred = model.predict(X)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_func(y_pred)\n",
    "        \n",
    "        # Update best sequence if current loss is better\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_X = X.copy()\n",
    "            best_y = y_pred\n",
    "        \n",
    "        # Compute gradient (using numerical approximation)\n",
    "        grad = np.zeros_like(X)\n",
    "        epsilon = 1e-3\n",
    "        for j in range(X.shape[1]):\n",
    "            X_plus = X.copy()\n",
    "            X_plus[0, j] += epsilon\n",
    "            y_pred_plus = model.predict(X_plus)\n",
    "            loss_plus = loss_func(y_pred_plus)\n",
    "            grad[0, j] = (loss_plus - loss) / epsilon\n",
    "        \n",
    "        # Clip gradients\n",
    "        grad = np.clip(grad, -grad_clip, grad_clip)\n",
    "        \n",
    "        # Update X using gradient descent\n",
    "        X -= learning_rate * grad\n",
    "        \n",
    "        # Apply softmax normalization to each 4-element segment\n",
    "        if np.mean(X)>2:\n",
    "            for k in range(0, X.shape[1], 4):\n",
    "                X[0, k:k+4] = softmax(X[0, k:k+4])\n",
    "        \n",
    "        # Print best sequence and prediction every 2 iterations\n",
    "        if i % 2 == 0:\n",
    "            # Convert best_X to closest one-hot vectors\n",
    "            best_X_closest = best_X.copy()\n",
    "            for k in range(0, best_X_closest.shape[1], 4):\n",
    "                best_X_closest[0, k:k+4] = closest_one_hot(best_X_closest[0, k:k+4])\n",
    "            best_seq = convert_input_type(best_X_closest.reshape(-1, 4), \"strings\")\n",
    "            best_y_pred = model.predict(best_X_closest)  # Get the prediction of the best_X_closest\n",
    "            # print(f\"Iteration {i}, Best sequence: {best_seq}, Best prediction value: {best_y_pred}\")\n",
    "\n",
    "    # Convert best one-hot encoded array back to closest one-hot vectors\n",
    "    for k in range(0, best_X.shape[1], 4):\n",
    "        best_X[0, k:k+4] = closest_one_hot(best_X[0, k:k+4])\n",
    "    \n",
    "    best_y_pred = model.predict(best_X)  # Get the prediction of the best_X_closest\n",
    "    # print(f\"Final loss: {best_y_pred}\")\n",
    "\n",
    "\n",
    "    # Convert optimized one-hot encoded array back to DNA sequence\n",
    "    optimized_seq = convert_input_type(best_X.reshape(-1, 4), \"strings\")\n",
    "    return optimized_seq, best_y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T11:37:37.177307Z",
     "start_time": "2025-03-28T11:37:37.164923Z"
    }
   },
   "outputs": [],
   "source": [
    "#SSWM\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from typing import Callable, List\n",
    "import random\n",
    "\n",
    "def convert_input_type(seq, target_type):\n",
    "    mapping = {'A': [1, 0, 0, 0], 'C': [0, 1, 0, 0], 'G': [0, 0, 1, 0], 'T': [0, 0, 0, 1]}\n",
    "    if target_type == \"one_hot\":\n",
    "        one_hot = np.array([mapping[base] for base in seq]).flatten()\n",
    "        return one_hot\n",
    "    elif target_type == \"strings\":\n",
    "        reverse_mapping = {tuple(v): k for k, v in mapping.items()}\n",
    "        reshaped_seq = seq.reshape(-1, 4)\n",
    "        strings = ''.join([reverse_mapping[tuple(base)] for base in reshaped_seq])\n",
    "        return strings\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported target_type. Use 'one_hot' or 'strings'.\")\n",
    "\n",
    "def mutate_sequence(seq: str, mutation_rate: float = 0.1) -> str:\n",
    "    bases = ['A', 'C', 'G', 'T']\n",
    "    mutated_seq = list(seq)\n",
    "    for i in range(len(seq)):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_seq[i] = random.choice(bases)\n",
    "    return ''.join(mutated_seq)\n",
    "\n",
    "def SSWM_optimization(\n",
    "    seq: str,\n",
    "    model: MLPRegressor,\n",
    "    loss_func: Callable,\n",
    "    population_size: int = 10,\n",
    "    generations: int = 200,\n",
    "    mutation_rate: float = 0.1,\n",
    "    selection_size: int = 5  # Number of top sequences to retain\n",
    "):\n",
    "    \"\"\"\n",
    "    Sequence design using SSWM with MLPRegressor\n",
    "\n",
    "    Args:\n",
    "        seq: an initial DNA sequence as a string.\n",
    "        model: A trained MLPRegressor object\n",
    "        loss_func: A function to compute the loss\n",
    "        population_size: Number of sequences in the population\n",
    "        generations: Number of generations to evolve\n",
    "        mutation_rate: Probability of mutating each base in the sequence\n",
    "        selection_size: Number of top sequences to retain\n",
    "\n",
    "    Returns:\n",
    "        Optimized DNA sequence as a string and its prediction value.\n",
    "    \"\"\"\n",
    "    # Initialize population with the initial sequence\n",
    "    population = [seq] * population_size\n",
    "    best_seq = seq\n",
    "    best_y = model.predict(convert_input_type(seq, \"one_hot\").reshape(1, -1))\n",
    "    best_loss = loss_func(best_y)\n",
    "    # print(f\"Initial sequence: {seq}, Initial loss: {best_loss}\")\n",
    "    \n",
    "    for generation in range(generations):\n",
    "        # Mutate population\n",
    "        new_population = [mutate_sequence(seq, mutation_rate) for seq in population]\n",
    "        \n",
    "        # Evaluate fitness of the new population\n",
    "        fitness_scores = []\n",
    "        for new_seq in new_population:\n",
    "            X = convert_input_type(new_seq, \"one_hot\").reshape(1, -1).astype(float)\n",
    "            y_pred = model.predict(X)\n",
    "            loss = loss_func(y_pred)\n",
    "            fitness_scores.append((new_seq, y_pred, loss))\n",
    "        \n",
    "        # Select the best sequences in the current generation\n",
    "        fitness_scores.sort(key=lambda x: x[2])  # Sort by loss (ascending)\n",
    "        selected_population = fitness_scores[:selection_size]  # Select top sequences\n",
    "        \n",
    "        # Update global best sequence if current best is better\n",
    "        current_best_seq, current_best_y, current_best_loss = selected_population[0]\n",
    "        if current_best_loss < best_loss:\n",
    "            best_seq = current_best_seq\n",
    "            best_y = current_best_y\n",
    "            best_loss = current_best_loss\n",
    "        \n",
    "        # Update population with the top sequences\n",
    "        population = [seq for seq, _, _ in selected_population]\n",
    "        \n",
    "        # Fill the rest of the population with mutated versions of the best sequences\n",
    "        while len(population) < population_size:\n",
    "            population.append(mutate_sequence(best_seq, mutation_rate))\n",
    "        \n",
    "        # print(f\"Generation {generation}, Best sequence: {best_seq}, Best prediction value: {best_y}, Best loss: {best_loss}\")\n",
    "\n",
    "    return best_seq, best_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get optimal sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T11:50:26.338449Z",
     "start_time": "2025-03-28T11:50:26.324997Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class NKModel:\n",
    "    def __init__(self, data_path):\n",
    "        self.df = pd.read_csv(data_path)\n",
    "        self.model = None\n",
    "\n",
    "    def get_sampling(self, n_samples):\n",
    "#         sample_X = latin_sampling(n_samples)\n",
    "        sample_X = initial_sampling[:n_samples]\n",
    "        return sample_X\n",
    "\n",
    "    def build_model(self, sample_X):\n",
    "        onehot_X = [convert_input_type(i, \"one_hot\") for i in sample_X]\n",
    "        y = self.NK_surrogate(sample_X)\n",
    "        \n",
    "        # Define the parameter grid\n",
    "        param_grid = {\n",
    "            'hidden_layer_sizes': [\n",
    "                (10,),\n",
    "                (40, 10),\n",
    "                (100, 100, 20),\n",
    "                (10, 100, 100, 20)\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        \n",
    "        # Initialize the MLPRegressor\n",
    "        mlp = MLPRegressor(max_iter=1000, random_state=0)\n",
    "        \n",
    "        # Use GridSearchCV to perform 5-fold cross-validation\n",
    "        grid_search = GridSearchCV(estimator=mlp, param_grid=param_grid, cv=5, scoring='r2')\n",
    "        \n",
    "        # Fit the model\n",
    "        grid_search.fit(onehot_X, y)\n",
    "        \n",
    "        # Select the best model\n",
    "        self.model = grid_search.best_estimator_\n",
    "\n",
    "    def NK_surrogate(self, input):\n",
    "        genotype_to_phenotype = dict(zip(self.df['Genotype'], self.df['Phenotype']))\n",
    "        ordered_phenotypes = [genotype_to_phenotype.get(genotype) for genotype in input]\n",
    "        return np.array(ordered_phenotypes)\n",
    "\n",
    "    def loss_func(self, y_pred):\n",
    "        return -np.mean(y_pred)\n",
    "\n",
    "    def get_model(self, n_samples):\n",
    "        samples = self.get_sampling(n_samples)\n",
    "        self.build_model(samples)\n",
    "        return self.model\n",
    "\n",
    "    def random_screening(self, sample_for_model=1000, n_screens=100000):\n",
    "        model = self.get_model(sample_for_model)\n",
    "        sequences = random_sampling(n_screens)\n",
    "        evaluations = [(seq, model.predict(convert_input_type(seq, \"one_hot\").reshape(1, -1))) for seq in sequences]\n",
    "        sorted_evaluations = sorted(evaluations, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        top_100_sequences = sorted_evaluations[:100]\n",
    "        top_sequences = [seq for seq, score in top_100_sequences]\n",
    "        top_scores = [score[0] for seq, score in top_100_sequences]\n",
    "        return top_sequences, top_scores\n",
    "\n",
    "    def get_best_batch(self, sample_for_model=1000, batch_size=1000, method=\"SSWM\"):\n",
    "        batch = []\n",
    "        model = self.get_model(sample_for_model)\n",
    "        j=1\n",
    "        while j < batch_size:\n",
    "            seq = random_sampling(1)[0]\n",
    "            if method == \"gradient\":\n",
    "                optimized_seq, best_y_pred = gradient_descent_optimization(seq, model, self.loss_func)\n",
    "            elif method == \"SSWM\":\n",
    "                optimized_seq, best_y_pred = SSWM_optimization(seq, model, self.loss_func)\n",
    "            if optimized_seq not in [item[0] for item in batch]:\n",
    "                batch.append((optimized_seq, best_y_pred))\n",
    "            j = j+1\n",
    "        sequences = [item[0] for item in batch]\n",
    "        expression_levels = np.array([item[1][0] for item in batch])\n",
    "        return sequences, expression_levels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T11:50:30.922441Z",
     "start_time": "2025-03-28T11:50:30.919357Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('initial_LHS_2000.txt', 'r') as f:\n",
    "    initial_sampling=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T11:51:31.652576Z",
     "start_time": "2025-03-28T11:50:32.567313Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [01:11<03:35, 71.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.651414283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [02:36<02:38, 79.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6135825030425532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [04:33<01:36, 96.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6324833867254902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [06:29<00:00, 97.47s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6045631339302326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample sizes to iterate over\n",
    "sample_size = [1000, 1100, 1200, 1300]\n",
    "nk_model = NKModel('NK0.csv')\n",
    "\n",
    "\n",
    "# Loop through sample sizes and collect data\n",
    "for i in tqdm(sample_size):\n",
    "    sequences, expression_levels = nk_model.get_best_batch(sample_for_model=i, batch_size=100, method=\"gradient\")\n",
    "    real_expression_levels = nk_model.NK_surrogate(sequences)\n",
    "    dataframe_sequences = pd.DataFrame()\n",
    "    dataframe_sequences[\"sequence\"+str(i)] = sequences\n",
    "    dataframe_sequences[\"evaluation\"+str(i)] = expression_levels\n",
    "    dataframe_sequences[\"real\"+str(i)] = real_expression_levels\n",
    "    print(np.mean(real_expression_levels))\n",
    "    dataframe_sequences.to_csv('NK0_gd_'+str(i)+'lhs.csv', index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T11:40:50.365327Z",
     "start_time": "2025-03-28T11:40:33.690917Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [01:22<04:07, 82.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5882566535833332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [02:47<02:47, 83.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5969569039814814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [04:10<01:23, 83.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5909328331607143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [05:25<00:00, 81.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6774279239444445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample sizes to iterate over\n",
    "sample_size = [1000, 1100, 1200, 1300]\n",
    "nk_model = NKModel('NK1.csv')\n",
    "\n",
    "\n",
    "# Loop through sample sizes and collect data\n",
    "for i in tqdm(sample_size):\n",
    "    sequences, expression_levels = nk_model.get_best_batch(sample_for_model=i, batch_size=100, method=\"gradient\")\n",
    "    real_expression_levels = nk_model.NK_surrogate(sequences)\n",
    "    dataframe_sequences = pd.DataFrame()\n",
    "    dataframe_sequences[\"sequence\"+str(i)] = sequences\n",
    "    dataframe_sequences[\"evaluation\"+str(i)] = expression_levels\n",
    "    dataframe_sequences[\"real\"+str(i)] = real_expression_levels\n",
    "    print(np.mean(real_expression_levels))\n",
    "    \n",
    "    dataframe_sequences.to_csv('NK1_gd_'+str(i)+'lhs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T11:40:50.366183Z",
     "start_time": "2025-03-28T11:40:50.366176Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [01:24<04:14, 84.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49042211283529413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [02:49<02:49, 84.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48231086713698634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [04:13<01:24, 84.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5257241310684931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [05:28<00:00, 82.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5546363916777779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample sizes to iterate over\n",
    "sample_size = [1000, 1100, 1200, 1300]\n",
    "nk_model = NKModel('NK2.csv')\n",
    "\n",
    "\n",
    "# Loop through sample sizes and collect data\n",
    "for i in tqdm(sample_size):\n",
    "    sequences, expression_levels = nk_model.get_best_batch(sample_for_model=i, batch_size=100, method=\"gradient\")\n",
    "    real_expression_levels = nk_model.NK_surrogate(sequences)\n",
    "    dataframe_sequences = pd.DataFrame()\n",
    "    dataframe_sequences[\"sequence\"+str(i)] = sequences\n",
    "    dataframe_sequences[\"evaluation\"+str(i)] = expression_levels\n",
    "    dataframe_sequences[\"real\"+str(i)] = real_expression_levels\n",
    "    print(np.mean(real_expression_levels))\n",
    "    \n",
    "    dataframe_sequences.to_csv('NK2_gd_'+str(i)+'lhs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T11:40:50.366710Z",
     "start_time": "2025-03-28T11:40:50.366704Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [01:24<04:14, 84.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5280128250967742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [02:48<02:48, 84.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.52778175975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [04:11<01:23, 83.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5207579315357143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [05:37<00:00, 84.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5219012153258427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample sizes to iterate over\n",
    "sample_size = [1000, 1100, 1200, 1300]\n",
    "nk_model = NKModel('NK3.csv')\n",
    "\n",
    "\n",
    "# Loop through sample sizes and collect data\n",
    "for i in tqdm(sample_size):\n",
    "    sequences, expression_levels = nk_model.get_best_batch(sample_for_model=i, batch_size=100, method=\"gradient\")\n",
    "    real_expression_levels = nk_model.NK_surrogate(sequences)\n",
    "    dataframe_sequences = pd.DataFrame()\n",
    "    dataframe_sequences[\"sequence\"+str(i)] = sequences\n",
    "    dataframe_sequences[\"evaluation\"+str(i)] = expression_levels\n",
    "    dataframe_sequences[\"real\"+str(i)] = real_expression_levels\n",
    "    print(np.mean(real_expression_levels))\n",
    "    \n",
    "    dataframe_sequences.to_csv('NK3_gd_'+str(i)+'lhs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T13:37:24.384542Z",
     "start_time": "2025-02-28T13:36:17.632756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6655472177900001\n",
      "0.6826985334099999\n",
      "0.6857966013699999\n",
      "0.6798443576200001\n"
     ]
    }
   ],
   "source": [
    "sample_size = [1000, 1100, 1200, 1300]\n",
    "nk_model = NKModel('NK0.csv')\n",
    "dataframe_sequences = pd.DataFrame()\n",
    "\n",
    "for i in sample_size:\n",
    "    sequences, expression_levels = nk_model.random_screening(sample_for_model=i)\n",
    "    real_expression_levels = nk_model.NK_surrogate(sequences)\n",
    "    dataframe_sequences[\"sequence\"+str(i)] = sequences\n",
    "    dataframe_sequences[\"evaluation\"+str(i)] = expression_levels\n",
    "    dataframe_sequences[\"real\"+str(i)] = real_expression_levels\n",
    "    print(np.mean(real_expression_levels))\n",
    "dataframe_sequences.to_csv('NK0_random_rd1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T13:38:28.931964Z",
     "start_time": "2025-02-28T13:37:24.385520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64034856123\n",
      "0.71114601482\n",
      "0.7224730678\n",
      "0.7233445157299999\n"
     ]
    }
   ],
   "source": [
    "sample_size = [1000, 1100, 1200, 1300]\n",
    "nk_model = NKModel('NK1.csv')\n",
    "dataframe_sequences = pd.DataFrame()\n",
    "\n",
    "for i in sample_size:\n",
    "    sequences, expression_levels = nk_model.random_screening(sample_for_model=i)\n",
    "    real_expression_levels = nk_model.NK_surrogate(sequences)\n",
    "    dataframe_sequences[\"sequence\"+str(i)] = sequences\n",
    "    dataframe_sequences[\"evaluation\"+str(i)] = expression_levels\n",
    "    dataframe_sequences[\"real\"+str(i)] = real_expression_levels\n",
    "    print(np.mean(real_expression_levels))\n",
    "dataframe_sequences.to_csv('NK1_random_rd1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T13:39:33.007801Z",
     "start_time": "2025-02-28T13:38:28.932927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.56615744338\n",
      "0.6043814477599999\n",
      "0.5993531395399999\n",
      "0.60061798551\n"
     ]
    }
   ],
   "source": [
    "sample_size = [1000, 1100, 1200, 1300]\n",
    "nk_model = NKModel('NK2.csv')\n",
    "dataframe_sequences = pd.DataFrame()\n",
    "\n",
    "for i in sample_size:\n",
    "    sequences, expression_levels = nk_model.random_screening(sample_for_model=i)\n",
    "    real_expression_levels = nk_model.NK_surrogate(sequences)\n",
    "    dataframe_sequences[\"sequence\"+str(i)] = sequences\n",
    "    dataframe_sequences[\"evaluation\"+str(i)] = expression_levels\n",
    "    dataframe_sequences[\"real\"+str(i)] = real_expression_levels\n",
    "    print(np.mean(real_expression_levels))\n",
    "dataframe_sequences.to_csv('NK2_random_rd1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T13:40:44.721373Z",
     "start_time": "2025-02-28T13:39:33.008726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55733073215\n",
      "0.5544379528400001\n",
      "0.54615851903\n",
      "0.55444800694\n"
     ]
    }
   ],
   "source": [
    "sample_size = [1000, 1100, 1200, 1300]\n",
    "nk_model = NKModel('NK3.csv')\n",
    "dataframe_sequences = pd.DataFrame()\n",
    "\n",
    "for i in sample_size:\n",
    "    sequences, expression_levels = nk_model.random_screening(sample_for_model=i)\n",
    "    real_expression_levels = nk_model.NK_surrogate(sequences)\n",
    "    dataframe_sequences[\"sequence\"+str(i)] = sequences\n",
    "    dataframe_sequences[\"evaluation\"+str(i)] = expression_levels\n",
    "    dataframe_sequences[\"real\"+str(i)] = real_expression_levels\n",
    "    print(np.mean(real_expression_levels))\n",
    "dataframe_sequences.to_csv('NK3_random_rd1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "AL",
   "language": "python",
   "name": "al"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
